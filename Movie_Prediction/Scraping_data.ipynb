{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Comedy Movie Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a database of 876 comedy movies on Box Office Mojo across 17 different comedy sub categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the genres page from box office mojo. This lists movies subgenres (comedy- spoof, comedy- road trip, comedy- spy, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www.boxofficemojo.com/genres/'\n",
    "response = requests.get(url)\n",
    "\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page,\"lxml\")\n",
    "\n",
    "#print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def comedy_links(soup):\n",
    "    '''create a list of link ends that go to comedy genre pages'''\n",
    "    comedy_links = []\n",
    "    for elem in soup.find_all('a', href=re.compile('comedy')):\n",
    "        comedy_links.append(elem['href'])\n",
    "    return comedy_links\n",
    "\n",
    "#print comedy_links(soup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def link_join(first_half, second_half):\n",
    "    \"create a list of full links that go to comedy subpages from movie genre page\"\n",
    "    links = []\n",
    "    for url in second_half:\n",
    "        links.append(first_half + url)\n",
    "    return links\n",
    "    \n",
    "\n",
    "genre_links = []\n",
    "genre_links = (link_join(\"http://www.boxofficemojo.com/genres/\", comedy_links(soup)))\n",
    "#print genre_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def open_genre_links(links):\n",
    "    movie_links = []\n",
    "    '''open up the link for each subgenre on the genre page and then return second \n",
    "    half of movie link for all comedy movies in box office mojo'''\n",
    "    for link in links:\n",
    "        #url = link\n",
    "        response = requests.get(link)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page,\"lxml\")\n",
    "        \n",
    "        for elem in soup.find_all('a', href=re.compile('/movies//?')):\n",
    "            movie_links.append(elem['href'])\n",
    "    return movie_links\n",
    "\n",
    "\n",
    "\"\"\"<a href=\"/movies/?id=meninblack.htm\"><b>Men in Black</b></a>\"\"\"\n",
    "second_half_movie_links = open_genre_links(genre_links)\n",
    "#print second_half_movie_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def link_join_movie_names(first_half, second_half):\n",
    "    \"return a list of full links that go to comedy movie pages from movie subgenre pages\"\n",
    "    links = []\n",
    "    for url in second_half:\n",
    "        links.append(first_half + url)\n",
    "    return links\n",
    "\n",
    "movie_links = link_join_movie_names(\"http://www.boxofficemojo.com\", second_half_movie_links)\n",
    "#remove duplicates-\n",
    "movie_links = set(movie_links)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be about 925 movie links stored in the movie_links list. Each link goes to the page of a comedy movie, where each feature will be extracted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tester_links(links):\n",
    "    '''creates smaller list of movie_links to test the build_df function below'''\n",
    "    links = list(links)\n",
    "    test_links = []\n",
    "    for i in range(10):\n",
    "        test_links.append(links[i])\n",
    "    return test_links\n",
    "\n",
    "tester_links = tester_links(movie_links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movie_value(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj: \n",
    "        return None\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dateutil.parser\n",
    "\n",
    "def to_date(datestring):\n",
    "    date = dateutil.parser.parse(datestring)\n",
    "    return date\n",
    "\n",
    "def money_to_int(moneystring):\n",
    "    try:\n",
    "        moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "        return int(moneystring)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def runtime_to_minutes(runtimestring):\n",
    "    runtime = runtimestring.split()\n",
    "    try:\n",
    "        minutes = int(runtime[0])*60 + int(runtime[2])\n",
    "        return minutes\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_df(links):\n",
    "    \"\"\"returns a dataframe of all scraped data\"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for link in links:\n",
    "        #open link\n",
    "        response = requests.get(link)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page,\"lxml\")\n",
    "        #scrape title\n",
    "        title_string = soup.find('title').text\n",
    "        title = title_string.split('(')[0].strip()\n",
    "        #scrape domestic total gross\n",
    "        domestic_total_gross = get_movie_value(soup,'Domestic Total')\n",
    "        domestic_total_gross = money_to_int(domestic_total_gross)\n",
    "        #scrape runtime\n",
    "        runtime = get_movie_value(soup,'Runtime')\n",
    "        #runtime = runtime_to_minutes(runtime)\n",
    "        #scrape rating\n",
    "        rating = get_movie_value(soup, \"MPAA Rating\")\n",
    "        #scrape release date and turn into datetime function\n",
    "        release_date = get_movie_value(soup, 'Release Date')\n",
    "        #release_date = to_date(release_date)\n",
    "        #scrapte distributor\n",
    "        distributor = get_movie_value(soup, \"Distributor\")\n",
    "        #scrape budget\n",
    "        budget = get_movie_value(soup, \"Production Budget\")\n",
    "        #scrape genre\n",
    "        genre = get_movie_value(soup, \"Genre:\")\n",
    "        #scrape opening weekend revenue\n",
    "        worldwide_total_gross = get_movie_value(soup, \"Worldwide: \")\n",
    "        #add row to data frame\n",
    "        df = df.append({\"runtime\" : runtime,\n",
    "                        \"title\": title,\n",
    "                        \"domestic_total_gross\": domestic_total_gross,\n",
    "                       \"rating\": rating,\n",
    "                       \"release_date\": release_date,\n",
    "                       \"distributor\": distributor,\n",
    "                       \"budget\" : budget,\n",
    "                       \"genre\" : genre\n",
    "                       }, ignore_index=True)\n",
    "    return df\n",
    "        #break \n",
    "        \n",
    "\n",
    "#print build_df(movie_links, df)\n",
    "'''test build_df function on smaller list'''\n",
    "df = build_df(movie_links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store df in pickle file\n",
    "with open('df_box_office_mojo.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.budget.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.release_date = str(df['release_date'])\n",
    "#df.release_date = pd.to_datetime(df['release_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a dataframe of box office mojo data has been scrapped and orangized, we can add additional data from IMDd and Rotten Tomatoes. An API can be used to find data for each movie. This will then be stored and added to the greated data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def movie_titles(df):\n",
    "    \"\"\"takes the data frame of features and returns title in format to use with IMDB api\"\"\"\n",
    "    movie_titles = df['title'].tolist()\n",
    "    movie_titles2 = []\n",
    "    #imdb_links = []\n",
    "    #return movie_titles\n",
    "    for movie in movie_titles:\n",
    "        movie = str(movie)\n",
    "        movie = urllib.quote_plus(movie)\n",
    "        movie_titles2.append(movie)\n",
    "        #movie_titles2.append(movie)\n",
    "    #imdb_links.append(\"http://www.omdbapi.com/?t=\"+)\n",
    "    return movie_titles2\n",
    "\n",
    "movie_titles = movie_titles(df)\n",
    "#print movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def api_link(movie_titles):\n",
    "    \"\"\"take the movie_titles list and returns api link for imdb\"\"\"\n",
    "    api_links = []\n",
    "    for movie in movie_titles:\n",
    "        api_links.append(\"http://www.omdbapi.com/?t=\" + movie)\n",
    "    return api_links\n",
    "\n",
    "api_links = api_link(movie_titles)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def api_tester_links(links):\n",
    "    '''creates smaller list of api_links to test the function below'''\n",
    "    #links = list(links)\n",
    "    test_links = []\n",
    "    for i in range(10):\n",
    "        #print links\n",
    "        test_links.append(links[i])\n",
    "    return test_links\n",
    "\n",
    "api_tester_links = api_tester_links(api_link(movie_titles))\n",
    "#print api_tester_links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the list of links for the api and open them to pull dictionaries for each movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use parameter to get rotten tomatoes rating \n",
    "parameters = dict(\n",
    "    tomatoes=True,\n",
    ")\n",
    "\n",
    "def imdb_api(links, parameters):\n",
    "    \"\"\"takes api links and parameters for api and returns dataframe for all movies\"\"\"\n",
    "    d = []\n",
    "    for url in links:\n",
    "        response = requests.get(url)\n",
    "        response = requests.get(url=url, params=parameters)\n",
    "        data = json.loads(response.text)\n",
    "        d.append(data)\n",
    "    return d\n",
    "\n",
    "\n",
    "d = imdb_api(api_links, parameters)\n",
    "#turn list of dictionaries into dataframe\n",
    "df_api = pd.DataFrame(d)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store df_api in pickle file\n",
    "with open('df_api.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(df_api, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the box office mojo and imdb data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change column name for title in df_api to merge with title in df from box office mojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_api = df_api.rename(columns = {'Title':'title'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df, df_api, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store merged df in pickle file\n",
    "with open('df_merge.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(df_merge, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing subplots on data already scraped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.figure(figsize=(15,10))\\nplt.plot_date(df.release_date, df.domestic_total_gross)\\nplt.xlabel('Runtime')\\nplt.ylabel('Domestic total gross')\\nplt.title('Domestic total gross by runtime')\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"plt.figure(figsize=(15,10))\n",
    "plt.plot_date(df.release_date, df.domestic_total_gross)\n",
    "plt.xlabel('Runtime')\n",
    "plt.ylabel('Domestic total gross')\n",
    "plt.title('Domestic total gross by runtime')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
